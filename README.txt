This is a very simple scraper which utilise a combination of beautiful soup and selenium. 

What does this scraper do?
This scrapper takes the 40 most affordable bass guitars from a website (guitarguitar.co.uk)
and compiles the name, price, in a CSV file. 
It all so compiles a folder of the images.
Both images and data are time and date stamped to keep log of when the data was compile.

What is the use of this scraper?
The idea is to run the scraper once or twice each day to see when you can find the best price for a bass guitar. 



Install requirements.txt using pip install -r requirements.txt in a virtual environment before running the webscraper

Ensure you have google chrome installed, and download chrome driver for the version of you google chrome.



